"""
WebRTC Real-time Video Streamer

Provides real-time video streaming using WebRTC for avatar responses.
This allows for low-latency, frame-by-frame video transmission.

Architecture:
- Signaling: WebSocket (port 9001) via frp tunnel to Web Server (port 19001)
- Media: WebRTC with custom STUN/TURN server (coturn on port 10110)
- TURN server handles NAT traversal and relay on ports 10110-10115
"""

import asyncio
import logging
import uuid
import re
import os
import time
from datetime import datetime
from typing import Optional, Dict
import numpy as np
import cv2
from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack, AudioStreamTrack, RTCIceServer, RTCConfiguration
from aiortc.contrib.media import MediaBlackhole
from av import VideoFrame, AudioFrame
import fractions
import socket
import base64
import io
import av

logger = logging.getLogger(__name__)

# å»¶è¿ŸåŠ è½½é…ç½®ï¼Œé¿å…å¾ªç¯å¯¼å…¥
_config = None

def get_webrtc_config():
    """è·å–WebRTCé…ç½®"""
    global _config
    if _config is None:
        from config import settings
        _config = {
            'public_ip': settings.webrtc_public_ip,
            'port_min': settings.webrtc_port_min,
            'port_max': settings.webrtc_port_max,
            'stun_server': settings.webrtc_stun_server,
            'turn_server': getattr(settings, 'webrtc_turn_server', 'turn:51.161.209.200:10110'),
            'turn_server_local': getattr(settings, 'webrtc_turn_server_local', 'turn:127.0.0.1:10110'),
            'turn_username': getattr(settings, 'webrtc_turn_username', 'vtuser'),
            'turn_password': getattr(settings, 'webrtc_turn_password', 'vtpass'),
        }
    return _config


# å…¨å±€å…±äº«å¯åŠ¨æ—¶é—´ - ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
_shared_start_time = None
# å…¨å±€æ•°æ®å°±ç»ªäº‹ä»¶ - å½“ process_frames_worker å¼€å§‹æ¨é€æ—¶è®¾ç½®
_data_ready_event = None
# æ˜¯å¦å·²è§¦å‘åŒæ­¥
_sync_triggered = False


def trigger_av_sync():
    """è§¦å‘éŸ³è§†é¢‘åŒæ­¥ - ç”± process_frames_worker åœ¨æ¨é€ç¬¬ä¸€å¸§æ—¶è°ƒç”¨"""
    global _shared_start_time, _data_ready_event, _sync_triggered
    
    if _sync_triggered:
        return
    
    _sync_triggered = True
    _shared_start_time = time.time()
    
    if _data_ready_event:
        # ä½¿ç”¨ call_soon_threadsafe åœ¨äº‹ä»¶å¾ªç¯ä¸­è®¾ç½®äº‹ä»¶
        try:
            loop = asyncio.get_event_loop()
            loop.call_soon_threadsafe(_data_ready_event.set)
        except:
            pass
    
    logger.info(f"ğŸ¬ AV sync triggered at {_shared_start_time}")


class AvatarVideoTrack(VideoStreamTrack):
    """
    Custom video track - å®Œå…¨ç…§æ¬ try/lip-sync/webrtc.py PlayerStreamTrack
    
    å…³é”®æ”¹åŠ¨ï¼š
    1. é˜Ÿåˆ—å­˜å‚¨ (frame, eventpoint) å…ƒç»„
    2. next_timestamp() æ§åˆ¶å¸§ç‡
    3. recv() ä½¿ç”¨ sleep ç­‰å¾…ï¼Œä¿æŒèŠ‚å¥
    4. ä¸ AvatarAudioTrack å…±äº« _start æ—¶é—´ç¡®ä¿åŒæ­¥
    """

    def __init__(self, idle_frames=None):
        super().__init__()
        # é˜Ÿåˆ—å­˜å‚¨ (frame, eventpoint) å…ƒç»„ - ç…§æ¬ try
        self._queue = asyncio.Queue()
        
        self._timestamp = None
        self._start = None
        self.current_frame_count = 0
        
        self.idle_frames = idle_frames or []
        self.idle_frame_index = 0
        
        # æ—¶é—´å¸¸é‡ - ä¸ try å®Œå…¨ä¸€è‡´
        self.VIDEO_PTIME = 0.040  # 40ms = 25fps
        self.VIDEO_CLOCK_RATE = 90000
        self.VIDEO_TIME_BASE = fractions.Fraction(1, self.VIDEO_CLOCK_RATE)
        
        # ç»Ÿè®¡
        self.framecount = 0
        self.lasttime = time.perf_counter()
        self.totaltime = 0
        
        # æ•°æ®å¼€å§‹æ ‡å¿— - æ”¶åˆ°å®é™…æ•°æ®å‰ä¸æ¨è¿›æ—¶é—´æˆ³
        self._data_started = False

    async def next_timestamp(self):
        """
        è®¡ç®—ä¸‹ä¸€å¸§çš„æ—¶é—´æˆ³
        """
        global _shared_start_time
        
        # å¦‚æœè¿˜æ²¡æ”¶åˆ°å®é™…æ•°æ®ï¼Œç­‰å¾…å¹¶è¿”å›æ—¶é—´æˆ³ 0
        if not self._data_started:
            await asyncio.sleep(self.VIDEO_PTIME)
            return 0, self.VIDEO_TIME_BASE
        
        if self._timestamp is not None:
            self._timestamp += int(self.VIDEO_PTIME * self.VIDEO_CLOCK_RATE)
            self.current_frame_count += 1
            
            # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
            wait = self._start + self.current_frame_count * self.VIDEO_PTIME - time.time()
            if wait > 0:
                await asyncio.sleep(wait)
        else:
            # ä½¿ç”¨å…±äº«å¯åŠ¨æ—¶é—´ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
            self._start = _shared_start_time if _shared_start_time else time.time()
            self._timestamp = 0
            logger.info(f"ğŸ“º Video track sync start: {self._start}")
        
        return self._timestamp, self.VIDEO_TIME_BASE
    
    async def recv(self):
        """
        æ¥æ”¶ä¸‹ä¸€å¸§ - æ”¶åˆ°å®é™…æ•°æ®å‰ç”¨ idle frameï¼Œæ”¶åˆ°åå¼€å§‹åŒæ­¥
        """
        # å°è¯•ä»é˜Ÿåˆ—è·å–å¸§
        try:
            item = self._queue.get_nowait()
            
            if isinstance(item, tuple):
                frame, eventpoint = item
            else:
                frame = item
            
            if frame is not None:
                # æ”¶åˆ°å®é™…æ•°æ®ï¼Œæ ‡è®°å¼€å§‹
                if not self._data_started:
                    self._data_started = True
                    logger.info("ğŸ“º Video: First real frame received, starting sync")
            else:
                frame = self._get_idle_frame()
            
        except asyncio.QueueEmpty:
            frame = self._get_idle_frame()
        
        # è®¡ç®—æ—¶é—´æˆ³
        pts, time_base = await self.next_timestamp()
        frame.pts = pts
        frame.time_base = time_base
        
        # ç»Ÿè®¡ FPS
        self.totaltime += (time.perf_counter() - self.lasttime)
        self.framecount += 1
        self.lasttime = time.perf_counter()
        
        if self.framecount == 100:
            logger.info(f"ğŸ“º Video avg fps: {self.framecount/self.totaltime:.2f}")
            self.framecount = 0
            self.totaltime = 0
        
        return frame
    
    def _get_idle_frame(self):
        """è·å– idle frame"""
        if self.idle_frames and len(self.idle_frames) > 0:
            idle_frame = self.idle_frames[self.idle_frame_index]
            self.idle_frame_index = (self.idle_frame_index + 1) % len(self.idle_frames)
            return VideoFrame.from_ndarray(idle_frame, format="bgr24")
        else:
            return VideoFrame.from_ndarray(np.zeros((512, 512, 3), dtype=np.uint8), format="bgr24")

    def set_idle_frames(self, frames: list):
        """è®¾ç½®å¾…æœºå¸§"""
        self.idle_frames = frames
        self.idle_frame_index = 0
        logger.info(f"Set {len(frames)} idle frames for WebRTC track")
    
    async def end_stream(self):
        """ç»“æŸæµ"""
        await self._queue.put((None, None))


class AvatarAudioTrack(AudioStreamTrack):
    """
    Audio track - ç…§æ¬ try/lip-sync/webrtc.py PlayerStreamTrack (audio)
    """

    def __init__(self):
        super().__init__()
        # é˜Ÿåˆ—å­˜å‚¨ (frame, eventpoint) å…ƒç»„ - ç…§æ¬ try
        self._queue = asyncio.Queue()
        
        self._timestamp = None
        self._start = None
        self.current_frame_count = 0
        
        # æ—¶é—´å¸¸é‡ - ä¸ try å®Œå…¨ä¸€è‡´
        self.AUDIO_PTIME = 0.020  # 20ms
        self.SAMPLE_RATE = 16000
        self.AUDIO_TIME_BASE = fractions.Fraction(1, self.SAMPLE_RATE)
        
        # æ•°æ®å¼€å§‹æ ‡å¿— - æ”¶åˆ°å®é™…æ•°æ®å‰ä¸æ¨è¿›æ—¶é—´æˆ³
        self._data_started = False
    
    async def next_timestamp(self):
        """è®¡ç®—ä¸‹ä¸€å¸§çš„æ—¶é—´æˆ³ - ä¸è§†é¢‘åŒæ­¥"""
        global _shared_start_time
        
        # å¦‚æœè¿˜æ²¡æ”¶åˆ°å®é™…æ•°æ®ï¼Œç­‰å¾…å¹¶è¿”å›æ—¶é—´æˆ³ 0
        if not self._data_started:
            await asyncio.sleep(self.AUDIO_PTIME)
            return 0, self.AUDIO_TIME_BASE
        
        if self._timestamp is not None:
            self._timestamp += int(self.AUDIO_PTIME * self.SAMPLE_RATE)
            self.current_frame_count += 1
            
            # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
            wait = self._start + self.current_frame_count * self.AUDIO_PTIME - time.time()
            if wait > 0:
                await asyncio.sleep(wait)
        else:
            # ä½¿ç”¨å…±äº«å¯åŠ¨æ—¶é—´ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
            self._start = _shared_start_time if _shared_start_time else time.time()
            self._timestamp = 0
            logger.info(f"ğŸ”Š Audio track sync start: {self._start}")
        
        return self._timestamp, self.AUDIO_TIME_BASE
    
    async def recv(self):
        """æ¥æ”¶ä¸‹ä¸€ä¸ªéŸ³é¢‘å¸§ - æ”¶åˆ°å®é™…æ•°æ®å‰ç”¨é™éŸ³ï¼Œæ”¶åˆ°åå¼€å§‹åŒæ­¥"""
        # å°è¯•ä»é˜Ÿåˆ—è·å–å¸§
        try:
            item = self._queue.get_nowait()
            
            if isinstance(item, tuple):
                frame, eventpoint = item
            else:
                frame = item
            
            if frame is not None:
                # æ”¶åˆ°å®é™…æ•°æ®ï¼Œæ ‡è®°å¼€å§‹
                if not self._data_started:
                    self._data_started = True
                    logger.info("ğŸ”Š Audio: First real frame received, starting sync")
            else:
                frame = self._get_silence_frame()
            
        except asyncio.QueueEmpty:
            frame = self._get_silence_frame()
        
        # è®¡ç®—æ—¶é—´æˆ³
        pts, time_base = await self.next_timestamp()
        frame.pts = pts
        frame.time_base = time_base
        return frame
    
    def _get_silence_frame(self):
        """è·å–é™éŸ³å¸§"""
        silence = np.zeros(320, dtype=np.int16)
        frame = AudioFrame(format='s16', layout='mono', samples=320)
        frame.planes[0].update(silence.tobytes())
        frame.sample_rate = 16000
        return frame


class WebRTCStreamer:
    """
    WebRTC Streamer for real-time avatar video

    Manages WebRTC peer connections and video streaming.
    """

    def __init__(self):
        self.connections: Dict[str, RTCPeerConnection] = {}
        self.video_tracks: Dict[str, AvatarVideoTrack] = {}
        self.audio_tracks: Dict[str, AvatarAudioTrack] = {}  # éŸ³é¢‘è½¨é“å­—å…¸
        self.websockets: Dict[str, any] = {}  # Store WebSocket connections for sending ICE candidates
        logger.info("WebRTC Streamer initialized with custom STUN/TURN server")

    async def create_peer_connection(self, session_id: str, idle_frames=None, websocket=None) -> RTCPeerConnection:
        """
        Create a new WebRTC peer connection

        Args:
            session_id: Session identifier
            idle_frames: Optional list of idle video frames for looping
            websocket: WebSocket connection for sending ICE candidates

        Returns:
            RTCPeerConnection: New peer connection
        """
        # é‡ç½®å…±äº«å¯åŠ¨æ—¶é—´å’Œæ•°æ®å°±ç»ªäº‹ä»¶ - ç¡®ä¿æ¯ä¸ªæ–°è¿æ¥çš„éŸ³è§†é¢‘åŒæ­¥
        global _shared_start_time, _data_ready_event, _sync_triggered
        _shared_start_time = None
        _data_ready_event = asyncio.Event()
        _sync_triggered = False
        
        # è·å–WebRTCé…ç½®
        config = get_webrtc_config()

        # é…ç½® TURN æœåŠ¡å™¨
        # âš ï¸ å…³é”®ï¼šGPUæœåŠ¡å™¨å¿…é¡»ä½¿ç”¨æœ¬åœ° TURN åœ°å€ (127.0.0.1)
        # å› ä¸º GPU æœåŠ¡å™¨åœ¨ Docker å®¹å™¨å†…ï¼Œæ— æ³•ä»å†…éƒ¨è¿æ¥åˆ°è‡ªå·±çš„å…¬ç½‘ IP
        local_turn = config['turn_server_local']  # turn:127.0.0.1:10110
        ice_servers = [
            RTCIceServer(
                urls=[config['stun_server']],
            ),
            RTCIceServer(
                urls=[local_turn],  # ä½¿ç”¨æœ¬åœ° TURN åœ°å€
                username=config['turn_username'],
                credential=config['turn_password']
            )
        ]

        # aiortc çš„ RTCConfiguration åªæ”¯æŒ iceServers å’Œ bundlePolicy
        configuration = RTCConfiguration(
            iceServers=ice_servers
        )

        logger.info(f"WebRTC configuration for session {session_id}:")
        logger.info(f"  STUN server: {config['stun_server']}")
        logger.info(f"  TURN server (GPU local): {local_turn}")
        logger.info(f"  TURN server (frontend): {config['turn_server']}")
        logger.info(f"  TURN username: {config['turn_username']}")
        logger.info(f"  Port range: {config['port_min']}-{config['port_max']}")

        pc = RTCPeerConnection(configuration=configuration)
        self.connections[session_id] = pc

        # Store WebSocket for sending ICE candidates
        if websocket:
            self.websockets[session_id] = websocket

        # é¢„å£°æ˜ transceiver (é¿å…åŠ¨æ€æ·»åŠ å¯¼è‡´ SDP åå•†å¤±è´¥)
        video_transceiver = pc.addTransceiver('video', direction='sendrecv')
        audio_transceiver = pc.addTransceiver('audio', direction='sendrecv')

        # åˆ›å»ºè§†é¢‘è½¨é“
        video_track = AvatarVideoTrack(idle_frames=idle_frames)
        self.video_tracks[session_id] = video_track

        # åˆ›å»ºéŸ³é¢‘è½¨é“
        audio_track = AvatarAudioTrack()
        self.audio_tracks[session_id] = audio_track

        # æ›¿æ¢ transceiver çš„ sender track
        video_transceiver.sender.replaceTrack(video_track)
        audio_transceiver.sender.replaceTrack(audio_track)

        @pc.on("connectionstatechange")
        async def on_connectionstatechange():
            logger.info(f"WebRTC connection state: {pc.connectionState}")
            
            # é€šçŸ¥å‰ç«¯è¿æ¥çŠ¶æ€å˜åŒ–
            if session_id in self.websockets:
                try:
                    await self.websockets[session_id].send_json({
                        "type": "webrtc_state",
                        "state": pc.connectionState,
                        "timestamp": datetime.now().isoformat()
                    })
                    logger.info(f"Sent WebRTC state to frontend: {pc.connectionState}")
                except Exception as e:
                    logger.error(f"Failed to send WebRTC state: {e}")
            
            if pc.connectionState == "failed" or pc.connectionState == "closed":
                await self.close_connection(session_id)

        @pc.on("icegatheringstatechange")
        async def on_icegatheringstatechange():
            logger.info(f"ICE gathering state: {pc.iceGatheringState}")

        logger.info(f"WebRTC peer connection created for session {session_id}")
        return pc

    async def _send_ice_candidates_from_sdp(self, sdp: str, session_id: str, websocket):
        """
        Extract ICE candidates from SDP and send them to the client

        aiortc includes ICE candidates in the SDP answer, but browsers
        expect to receive them via onicecandidate events. This method
        extracts candidates from SDP and sends them separately.

        Args:
            sdp: SDP string containing ICE candidates
            session_id: Session identifier
            websocket: WebSocket connection for sending candidates
        """
        try:
            lines = sdp.split('\n')
            sdp_mline_index = -1
            sdp_mid = None

            for line in lines:
                # Track media line index
                if line.startswith('m='):
                    sdp_mline_index += 1

                # Extract mid from a=mid line
                if line.startswith('a=mid:'):
                    sdp_mid = line.split(':', 1)[1].strip()

                # Extract ICE candidates
                if line.startswith('a=candidate:'):
                    candidate_str = line[2:]  # Remove 'a=' prefix

                    # Log full candidate for debugging
                    logger.info(f"Full candidate from SDP: {candidate_str}")

                    # åªå‘é€ relay ç±»å‹çš„ candidates åˆ°å‰ç«¯
                    # åŸå› ï¼šåªæœ‰ 10110-10115 ç«¯å£è¢«æ˜ å°„åˆ°å…¬ç½‘ï¼Œå…¶ä»–ç«¯å£æ— æ³•ä»å¤–éƒ¨è®¿é—®
                    if 'typ relay' not in candidate_str:
                        logger.info(f"Skipping non-relay candidate (port not accessible): {candidate_str[:60]}...")
                        continue

                    # Send candidate to client
                    await websocket.send_json({
                        "type": "webrtc_ice_candidate",
                        "candidate": {
                            "candidate": candidate_str,
                            "sdpMLineIndex": sdp_mline_index,
                            "sdpMid": sdp_mid
                        }
                    })
                    logger.info(f"Sent relay ICE candidate to client for session {session_id}: {candidate_str[:60]}...")

            logger.info(f"Finished sending ICE candidates for session {session_id}")
        except Exception as e:
            logger.error(f"Failed to extract and send ICE candidates: {e}")

    def _modify_sdp_for_public_ip(self, sdp: str) -> str:
        """
        ä¿®æ”¹SDPï¼Œå°†å†…ç½‘IPæ›¿æ¢ä¸ºå…¬ç½‘IPï¼Œå¹¶åªä¿ç•™relayç±»å‹çš„candidates

        Args:
            sdp: åŸå§‹SDPå­—ç¬¦ä¸²

        Returns:
            str: ä¿®æ”¹åçš„SDPå­—ç¬¦ä¸²
        """
        config = get_webrtc_config()
        public_ip = config['public_ip']

        # æ›¿æ¢ c= è¡Œä¸­çš„IPåœ°å€
        # c=IN IP4 192.168.x.x -> c=IN IP4 51.161.209.200
        sdp = re.sub(r'c=IN IP4 \d+\.\d+\.\d+\.\d+', f'c=IN IP4 {public_ip}', sdp)

        # è¿‡æ»¤candidatesï¼šåªä¿ç•™relayç±»å‹ï¼Œç§»é™¤hostå’Œsrflxç±»å‹
        # åŸå› ï¼šåªæœ‰ 10110-10115 ç«¯å£è¢«æ˜ å°„åˆ°å…¬ç½‘ï¼Œå…¶ä»–ç«¯å£ï¼ˆå¦‚ 39498ï¼‰æ— æ³•è®¿é—®
        lines = sdp.split('\n')
        modified_lines = []

        for line in lines:
            if line.startswith('a=candidate'):
                # åªä¿ç•™ typ relay çš„ candidates
                if 'typ relay' in line:
                    modified_lines.append(line)
                    logger.debug(f"Keeping relay candidate: {line}")
                else:
                    logger.debug(f"Removing non-relay candidate (inaccessible port): {line}")
            else:
                modified_lines.append(line)

        sdp = '\n'.join(modified_lines)
        logger.info(f"Modified SDP: replaced IPs with {public_ip}, kept only relay candidates")
        return sdp

    async def handle_offer(
        self,
        session_id: str,
        offer_sdp: str,
        idle_frames=None,
        websocket=None
    ) -> str:
        """
        Handle WebRTC offer from client

        Args:
            session_id: Session identifier
            offer_sdp: SDP offer from client
            idle_frames: Optional list of idle video frames for looping
            websocket: WebSocket connection for sending ICE candidates

        Returns:
            str: SDP answer
        """
        # Check if connection exists and is still open
        if session_id in self.connections:
            pc = self.connections[session_id]
            # If connection is closed, clean it up first
            if pc.connectionState == "closed" or pc.signalingState == "closed":
                logger.info(f"Cleaning up closed connection for session {session_id}")
                await self.close_connection(session_id)
        
        # Create peer connection if not exists (or was just cleaned up)
        if session_id not in self.connections:
            await self.create_peer_connection(session_id, idle_frames=idle_frames, websocket=websocket)

        pc = self.connections[session_id]

        # Set remote description (offer)
        offer = RTCSessionDescription(sdp=offer_sdp, type="offer")
        await pc.setRemoteDescription(offer)

        # Create answer
        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)

        # ç­‰å¾… ICE gathering å®Œæˆï¼ˆç¡®ä¿è·å–åˆ°æ‰€æœ‰candidatesåŒ…æ‹¬TURN relayï¼‰
        # å¦‚æœ gathering çŠ¶æ€å·²ç»æ˜¯ 'complete'ï¼Œè¿™ä¸ªå¾ªç¯ä¼šç«‹å³é€€å‡º
        max_wait = 5  # æœ€å¤šç­‰å¾…5ç§’
        waited = 0
        while pc.iceGatheringState != "complete" and waited < max_wait:
            await asyncio.sleep(0.1)
            waited += 0.1
        
        if pc.iceGatheringState != "complete":
            logger.warning(f"ICE gathering not complete after {max_wait}s, proceeding anyway")
        else:
            logger.info(f"ICE gathering completed in {waited:.2f}s")

        # ä¿®æ”¹SDPä»¥ä½¿ç”¨å…¬ç½‘IP
        modified_sdp = self._modify_sdp_for_public_ip(pc.localDescription.sdp)

        # Extract and send ICE candidates from SDP to client
        # aiortc includes ICE candidates in the SDP, but browsers expect them separately
        if websocket:
            await self._send_ice_candidates_from_sdp(modified_sdp, session_id, websocket)

        logger.info(f"WebRTC answer created for session {session_id}")
        return modified_sdp

    async def add_ice_candidate(
        self,
        session_id: str,
        candidate: dict
    ):
        """
        Add ICE candidate from client

        Args:
            session_id: Session identifier
            candidate: ICE candidate data (RTCIceCandidate object or dict)
        """
        if session_id in self.connections:
            pc = self.connections[session_id]
            try:
                # ä»å‰ç«¯ä¼ æ¥çš„candidateå¯èƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œéœ€è¦æå–å­—æ®µ
                if isinstance(candidate, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–candidateå­—æ®µ
                    candidate_str = candidate.get('candidate')
                    sdp_mid = candidate.get('sdpMid')
                    sdp_mline_index = candidate.get('sdpMLineIndex')
                else:
                    # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                    candidate_str = str(candidate)
                    sdp_mid = None
                    sdp_mline_index = None

                # ä½¿ç”¨aiortcçš„candidate_from_sdpè§£æcandidateå­—ç¬¦ä¸²
                from aiortc.sdp import candidate_from_sdp
                ice_candidate = candidate_from_sdp(candidate_str)

                # è®¾ç½®sdpMidå’ŒsdpMLineIndex
                ice_candidate.sdpMid = sdp_mid
                ice_candidate.sdpMLineIndex = sdp_mline_index

                await pc.addIceCandidate(ice_candidate)
                logger.info(f"ICE candidate added for session {session_id}: {candidate_str[:50] if candidate_str else 'None'}...")
            except Exception as e:
                logger.error(f"Failed to add ICE candidate for session {session_id}: {e}")
                logger.error(f"Candidate data: {candidate}")
        else:
            logger.warning(f"No connection found for session {session_id} when adding ICE candidate")

    async def stream_frame(self, session_id: str, frame: np.ndarray):
        """
        Stream a single frame to the client

        Args:
            session_id: Session identifier
            frame: numpy array (H, W, 3) in BGR format
        """
        if session_id in self.video_tracks:
            video_track = self.video_tracks[session_id]
            await video_track.add_frame(frame)
        else:
            logger.warning(f"No video track found for session {session_id}")

    async def prepare_audio_chunks(self, audio_base64: str) -> list:
        """
        é¢„å…ˆå‡†å¤‡éŸ³é¢‘ chunksï¼ˆç”¨äºåŒæ­¥æ¨é€ï¼‰
        ä¸ try çš„å®ç°ä¿æŒä¸€è‡´ï¼š16kHz, 320 samples/chunk

        Args:
            audio_base64: base64 encoded audio (MP3 or WAV)

        Returns:
            list: éŸ³é¢‘ chunk åˆ—è¡¨ï¼Œæ¯ä¸ª chunk æ˜¯ 320 samples (20ms @ 16kHz) çš„ numpy array
        """
        try:
            # è§£ç  base64
            audio_bytes = base64.b64decode(audio_base64)

            # ä½¿ç”¨ PyAV è§£ç éŸ³é¢‘
            container = av.open(io.BytesIO(audio_bytes))
            audio_stream = container.streams.audio[0]

            # é‡é‡‡æ ·åˆ° 16kHz, s16, monoï¼ˆä¸ try ä¿æŒä¸€è‡´ï¼‰
            resampler = av.audio.resampler.AudioResampler(
                format='s16',
                layout='mono',
                rate=16000  # 16kHz
            )

            chunks = []
            for packet in container.demux(audio_stream):
                for frame in packet.decode():
                    # é‡é‡‡æ ·
                    resampled_frames = resampler.resample(frame)

                    for resampled_frame in resampled_frames:
                        # è½¬æ¢ä¸º numpy array
                        audio_data = resampled_frame.to_ndarray()[0]  # (samples,)

                        # åˆ†å—ä¸º 320 samples (20ms @ 16kHz)
                        for i in range(0, len(audio_data), 320):
                            chunk = audio_data[i:i+320]
                            if len(chunk) == 320:
                                chunks.append(chunk)

            return chunks

        except Exception as e:
            logger.error(f"Failed to prepare audio chunks: {e}", exc_info=True)
            return []

    async def stream_audio(self, session_id: str, audio_base64: str):
        """
        Stream audio to WebRTC audio trackï¼ˆç‹¬ç«‹æ¨é€ï¼Œç”¨äºéåŒæ­¥åœºæ™¯ï¼‰

        Args:
            session_id: Session identifier
            audio_base64: base64 encoded audio (MP3 or WAV)
        """
        if session_id not in self.audio_tracks:
            logger.warning(f"Audio track not found for session {session_id}")
            return

        try:
            audio_track = self.audio_tracks[session_id]
            logger.info(f"[Audio] Starting audio preparation for {session_id}, audio_base64 length: {len(audio_base64)}")
            
            chunks = await self.prepare_audio_chunks(audio_base64)
            
            logger.info(f"[Audio] Prepared {len(chunks)} chunks for {session_id}")
            
            # é€ä¸ªæ¨é€ chunks
            for i, chunk in enumerate(chunks):
                await audio_track.add_audio_chunk(chunk)
                if i == 0:
                    logger.info(f"[Audio] âš¡ First chunk pushed")
                if (i + 1) % 50 == 0:
                    logger.info(f"[Audio] ğŸ“¤ Pushed {i + 1}/{len(chunks)} chunks")

            logger.info(f"[Audio] âœ… Completed: {len(chunks)} chunks (~{len(chunks) * 20}ms)")

        except Exception as e:
            logger.error(f"Failed to stream audio: {e}", exc_info=True)

    def set_idle_frames(self, session_id: str, frames: list):
        """
        Set idle video frames for a session

        Args:
            session_id: Session identifier
            frames: List of numpy arrays (H, W, 3) in BGR format
        """
        if session_id in self.video_tracks:
            video_track = self.video_tracks[session_id]
            video_track.set_idle_frames(frames)
        else:
            logger.warning(f"No video track found for session {session_id}")

    async def close_connection(self, session_id: str):
        """
        Close WebRTC connection

        Args:
            session_id: Session identifier
        """
        # æ£€æŸ¥è¿æ¥æ˜¯å¦å­˜åœ¨ï¼ˆé¿å…é‡å¤å…³é—­å¯¼è‡´ KeyErrorï¼‰
        if session_id not in self.connections:
            logger.debug(f"Connection {session_id} already closed or not found")
            return
        
        if session_id in self.video_tracks:
            track = self.video_tracks[session_id]
            if hasattr(track, 'end_stream'):
                try:
                    await track.end_stream()
                except Exception as e:
                    logger.debug(f"Error ending video stream: {e}")
            del self.video_tracks[session_id]

        if session_id in self.audio_tracks:
            del self.audio_tracks[session_id]

        if session_id in self.connections:
            await self.connections[session_id].close()
            del self.connections[session_id]
        
        # æ¸…ç† WebSocket å¼•ç”¨
        if session_id in self.websockets:
            del self.websockets[session_id]

        logger.info(f"WebRTC connection closed for session {session_id}")


# Global WebRTC streamer instance
_webrtc_streamer: Optional[WebRTCStreamer] = None


def get_webrtc_streamer() -> WebRTCStreamer:
    """
    Get global WebRTC streamer instance (singleton)

    Returns:
        WebRTCStreamer: Global streamer instance
    """
    global _webrtc_streamer

    if _webrtc_streamer is None:
        _webrtc_streamer = WebRTCStreamer()
        logger.info("WebRTC streamer initialized")

    return _webrtc_streamer
