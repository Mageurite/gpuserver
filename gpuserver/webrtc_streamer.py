"""
WebRTC Real-time Video Streamer

Provides real-time video streaming using WebRTC for avatar responses.
This allows for low-latency, frame-by-frame video transmission.

Architecture:
- Signaling: WebSocket (port 9001) via frp tunnel to Web Server (port 19001)
- Media: WebRTC with custom STUN/TURN server (coturn on port 10110)
- TURN server handles NAT traversal and relay on ports 10110-10115
"""

import asyncio
import logging
import uuid
import re
import os
import time
from datetime import datetime
from typing import Optional, Dict
import numpy as np
import cv2
from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack, AudioStreamTrack, RTCIceServer, RTCConfiguration
from aiortc.contrib.media import MediaBlackhole
from av import VideoFrame, AudioFrame
import fractions
import socket
import base64
import io
import av

logger = logging.getLogger(__name__)

# å»¶è¿ŸåŠ è½½é…ç½®ï¼Œé¿å…å¾ªç¯å¯¼å…¥
_config = None

def get_webrtc_config():
    """è·å–WebRTCé…ç½®"""
    global _config
    if _config is None:
        from config import settings
        _config = {
            'public_ip': settings.webrtc_public_ip,
            'port_min': settings.webrtc_port_min,
            'port_max': settings.webrtc_port_max,
            'stun_server': settings.webrtc_stun_server,
            'turn_server': getattr(settings, 'webrtc_turn_server', 'turn:51.161.209.200:10110'),
            'turn_server_local': getattr(settings, 'webrtc_turn_server_local', 'turn:127.0.0.1:10110'),
            'turn_username': getattr(settings, 'webrtc_turn_username', 'vtuser'),
            'turn_password': getattr(settings, 'webrtc_turn_password', 'vtpass'),
        }
    return _config


class AvatarVideoTrack(VideoStreamTrack):
    """
    Custom video track that streams avatar frames in real-time
    å‚è€ƒ: virtual-tutor/lip-sync/webrtc.py PlayerStreamTrack
    """

    def __init__(self, idle_frames=None):
        super().__init__()
        self.frame_queue = asyncio.Queue(maxsize=30)  # Buffer up to 30 frames
        self._timestamp = 0
        self._frame_count = 0
        self._start_time = None  # å¼€å§‹æ—¶é—´
        self.current_frame_count = 0  # å½“å‰å¸§è®¡æ•°
        self.idle_frames = idle_frames or []  # å¾…æœºè§†é¢‘å¸§åˆ—è¡¨
        self.idle_frame_index = 0  # å½“å‰å¾…æœºå¸§ç´¢å¼•
        self.is_streaming = False  # æ˜¯å¦æ­£åœ¨æµå¼ä¼ è¾“å¯¹è¯è§†é¢‘
        
        # æ—¶é—´å¸¸é‡ï¼ˆå‚è€ƒ virtual-tutorï¼‰
        self.VIDEO_PTIME = 1 / 25  # 25fps = 40ms per frame
        self.VIDEO_CLOCK_RATE = 90000

    async def recv(self):
        """
        Receive next video frame
        ç®€åŒ–ç‰ˆæœ¬ï¼šè®© aiortc è‡ªå·±æ§åˆ¶å¸§ç‡ï¼Œæˆ‘ä»¬åªè´Ÿè´£æä¾›å¸§æ•°æ®
        
        Returns:
            VideoFrame: Next frame to send to client
        """
        try:
            # å°è¯•ä»é˜Ÿåˆ—è·å–å¸§ï¼ˆéé˜»å¡ï¼ŒçŸ­è¶…æ—¶ï¼‰
            frame_data = await asyncio.wait_for(
                self.frame_queue.get(),
                timeout=0.04  # 40ms = 25fps
            )

            if frame_data is None:
                # End of stream signal
                raise StopAsyncIteration

            # æ ‡è®°ä¸ºæ­£åœ¨æµå¼ä¼ è¾“
            if not self.is_streaming:
                logger.info(f"ğŸ“º WebRTC track: Started streaming generated frames")
                self.is_streaming = True

            # Convert numpy array to VideoFrame
            frame = VideoFrame.from_ndarray(frame_data, format="bgr24")
            frame.pts = self._timestamp
            frame.time_base = fractions.Fraction(1, 90000)  # æ ‡å‡† RTP æ—¶é’Ÿé¢‘ç‡
            
            # é€’å¢ timestampï¼ˆæ¯å¸§ +3600 = 40ms @ 90kHzï¼‰
            self._timestamp += 3600
            self._frame_count += 1
            
            if self._frame_count % 20 == 0:
                logger.info(f"ğŸ“º WebRTC track: Sent {self._frame_count} frames (qsize={self.frame_queue.qsize()})")

            return frame

        except asyncio.TimeoutError:
            # é˜Ÿåˆ—ä¸ºç©ºï¼Œä½¿ç”¨å¾…æœºè§†é¢‘å¸§
            if self.idle_frames and len(self.idle_frames) > 0:
                # å¾ªç¯æ’­æ”¾å¾…æœºè§†é¢‘
                idle_frame = self.idle_frames[self.idle_frame_index]
                self.idle_frame_index = (self.idle_frame_index + 1) % len(self.idle_frames)

                frame = VideoFrame.from_ndarray(idle_frame, format="bgr24")
                frame.pts = self._timestamp
                frame.time_base = fractions.Fraction(1, 90000)
                self._timestamp += 3600  # 40ms @ 90kHz

                # å¦‚æœä¹‹å‰åœ¨æµå¼ä¼ è¾“ï¼Œç°åœ¨åˆ‡æ¢å›å¾…æœº
                if self.is_streaming:
                    logger.info("Switching back to idle video")
                    self.is_streaming = False

                return frame
            else:
                # æ²¡æœ‰å¾…æœºå¸§ï¼Œå‘é€é»‘å±
                black_frame = np.zeros((512, 512, 3), dtype=np.uint8)
                frame = VideoFrame.from_ndarray(black_frame, format="bgr24")
                frame.pts = self._timestamp
                frame.time_base = fractions.Fraction(1, 90000)
                self._timestamp += 3600
                return frame

    async def add_frame(self, frame: np.ndarray):
        """
        Add a frame to the streaming queue

        Args:
            frame: numpy array (H, W, 3) in BGR format
        """
        try:
            await self.frame_queue.put(frame)
        except asyncio.QueueFull:
            logger.warning("Frame queue full, dropping frame")

    def set_idle_frames(self, frames: list):
        """
        Set idle video frames for looping

        Args:
            frames: List of numpy arrays (H, W, 3) in BGR format
        """
        self.idle_frames = frames
        self.idle_frame_index = 0
        logger.info(f"Set {len(frames)} idle frames for WebRTC track")

    async def end_stream(self):
        """Signal end of stream"""
        await self.frame_queue.put(None)


class AvatarAudioTrack(AudioStreamTrack):
    """
    Custom audio track that streams TTS audio in real-time
    å‚è€ƒ: virtual-tutor/lip-sync/webrtc.py PlayerStreamTrack (audio)
    """

    def __init__(self):
        super().__init__()
        self.frame_queue = asyncio.Queue(maxsize=200)  # ç¼“å†²çº¦ 4 ç§’
        self._timestamp = 0
        self._sample_rate = 48000  # WebRTC æ ‡å‡†é‡‡æ ·ç‡
        self._samples_per_frame = 960  # 20ms @ 48kHz
        self._start_time = None
        self.current_frame_count = 0
        self.AUDIO_PTIME = 0.020  # 20ms audio packetization

    async def recv(self):
        """
        Receive next audio frame (æ¯ 20ms è°ƒç”¨ä¸€æ¬¡)
        ç®€åŒ–ç‰ˆæœ¬ï¼šè®© aiortc è‡ªå·±æ§åˆ¶å¸§ç‡
        
        Returns:
            AudioFrame: 960 samples @ 48kHz, s16, mono
        """
        try:
            # å°è¯•ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
            audio_samples = await asyncio.wait_for(
                self.frame_queue.get(),
                timeout=0.02  # 20ms
            )

            if audio_samples is None:
                # End of stream signal
                raise StopAsyncIteration

            # åˆ›å»º AudioFrame
            frame = AudioFrame(format='s16', layout='mono', samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = fractions.Fraction(1, self._sample_rate)

            # å¡«å……éŸ³é¢‘æ•°æ®
            frame.planes[0].update(audio_samples.tobytes())
            
            # é€’å¢ timestamp
            self._timestamp += self._samples_per_frame

            return frame

        except asyncio.TimeoutError:
            # é˜Ÿåˆ—ä¸ºç©º,å‘é€é™éŸ³å¸§
            silence = np.zeros(self._samples_per_frame, dtype=np.int16)
            frame = AudioFrame(format='s16', layout='mono', samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = fractions.Fraction(1, self._sample_rate)
            frame.planes[0].update(silence.tobytes())
            self._timestamp += self._samples_per_frame
            return frame

    async def add_audio_chunk(self, audio_samples: np.ndarray):
        """
        Add audio samples to the streaming queue

        Args:
            audio_samples: numpy array (960,) dtype=int16
        """
        try:
            await self.frame_queue.put(audio_samples)
        except asyncio.QueueFull:
            logger.warning("Audio queue full, dropping chunk")


class WebRTCStreamer:
    """
    WebRTC Streamer for real-time avatar video

    Manages WebRTC peer connections and video streaming.
    """

    def __init__(self):
        self.connections: Dict[str, RTCPeerConnection] = {}
        self.video_tracks: Dict[str, AvatarVideoTrack] = {}
        self.audio_tracks: Dict[str, AvatarAudioTrack] = {}  # éŸ³é¢‘è½¨é“å­—å…¸
        self.websockets: Dict[str, any] = {}  # Store WebSocket connections for sending ICE candidates
        logger.info("WebRTC Streamer initialized with custom STUN/TURN server")

    async def create_peer_connection(self, session_id: str, idle_frames=None, websocket=None) -> RTCPeerConnection:
        """
        Create a new WebRTC peer connection

        Args:
            session_id: Session identifier
            idle_frames: Optional list of idle video frames for looping
            websocket: WebSocket connection for sending ICE candidates

        Returns:
            RTCPeerConnection: New peer connection
        """
        # è·å–WebRTCé…ç½®
        config = get_webrtc_config()

        # é…ç½® TURN æœåŠ¡å™¨
        # âš ï¸ ä¿®æ”¹ï¼šGPUæœåŠ¡å™¨ä¹Ÿä½¿ç”¨å…¬ç½‘TURNåœ°å€ï¼ˆå®æµ‹å¯ä»¥è¿æ¥ï¼‰
        # è¿™æ ·GPUæœåŠ¡å™¨å’Œå‰ç«¯éƒ½ä½¿ç”¨ç›¸åŒçš„TURNæœåŠ¡å™¨åœ°å€
        ice_servers = [
            RTCIceServer(
                urls=[config['stun_server']],
            ),
            RTCIceServer(
                urls=[config['turn_server']],  # ä½¿ç”¨å…¬ç½‘TURNåœ°å€
                username=config['turn_username'],
                credential=config['turn_password']
            )
        ]

        # aiortc çš„ RTCConfiguration åªæ”¯æŒ iceServers å’Œ bundlePolicy
        configuration = RTCConfiguration(
            iceServers=ice_servers
        )

        logger.info(f"WebRTC configuration for session {session_id}:")
        logger.info(f"  STUN server: {config['stun_server']}")
        logger.info(f"  TURN server: {config['turn_server']} (public, used by both frontend and GPU server)")
        logger.info(f"  TURN username: {config['turn_username']}")
        logger.info(f"  Port range: {config['port_min']}-{config['port_max']}")
        logger.info(f"  Note: GPU server uses local TURN, frontend uses public TURN")

        pc = RTCPeerConnection(configuration=configuration)
        self.connections[session_id] = pc

        # Store WebSocket for sending ICE candidates
        if websocket:
            self.websockets[session_id] = websocket

        # é¢„å£°æ˜ transceiver (é¿å…åŠ¨æ€æ·»åŠ å¯¼è‡´ SDP åå•†å¤±è´¥)
        video_transceiver = pc.addTransceiver('video', direction='sendrecv')
        audio_transceiver = pc.addTransceiver('audio', direction='sendrecv')

        # åˆ›å»ºè§†é¢‘è½¨é“
        video_track = AvatarVideoTrack(idle_frames=idle_frames)
        self.video_tracks[session_id] = video_track

        # åˆ›å»ºéŸ³é¢‘è½¨é“
        audio_track = AvatarAudioTrack()
        self.audio_tracks[session_id] = audio_track

        # æ›¿æ¢ transceiver çš„ sender track
        video_transceiver.sender.replaceTrack(video_track)
        audio_transceiver.sender.replaceTrack(audio_track)

        @pc.on("connectionstatechange")
        async def on_connectionstatechange():
            logger.info(f"WebRTC connection state: {pc.connectionState}")
            
            # é€šçŸ¥å‰ç«¯è¿æ¥çŠ¶æ€å˜åŒ–
            if session_id in self.websockets:
                try:
                    await self.websockets[session_id].send_json({
                        "type": "webrtc_state",
                        "state": pc.connectionState,
                        "timestamp": datetime.now().isoformat()
                    })
                    logger.info(f"Sent WebRTC state to frontend: {pc.connectionState}")
                except Exception as e:
                    logger.error(f"Failed to send WebRTC state: {e}")
            
            if pc.connectionState == "failed" or pc.connectionState == "closed":
                await self.close_connection(session_id)

        @pc.on("icegatheringstatechange")
        async def on_icegatheringstatechange():
            logger.info(f"ICE gathering state: {pc.iceGatheringState}")

        logger.info(f"WebRTC peer connection created for session {session_id}")
        return pc

    async def _send_ice_candidates_from_sdp(self, sdp: str, session_id: str, websocket):
        """
        Extract ICE candidates from SDP and send them to the client

        aiortc includes ICE candidates in the SDP answer, but browsers
        expect to receive them via onicecandidate events. This method
        extracts candidates from SDP and sends them separately.

        Args:
            sdp: SDP string containing ICE candidates
            session_id: Session identifier
            websocket: WebSocket connection for sending candidates
        """
        try:
            lines = sdp.split('\n')
            sdp_mline_index = -1
            sdp_mid = None

            for line in lines:
                # Track media line index
                if line.startswith('m='):
                    sdp_mline_index += 1

                # Extract mid from a=mid line
                if line.startswith('a=mid:'):
                    sdp_mid = line.split(':', 1)[1].strip()

                # Extract ICE candidates
                if line.startswith('a=candidate:'):
                    candidate_str = line[2:]  # Remove 'a=' prefix

                    # Log full candidate for debugging
                    logger.info(f"Full candidate from SDP: {candidate_str}")

                    # åªå‘é€ relay ç±»å‹çš„ candidates åˆ°å‰ç«¯
                    # åŸå› ï¼šåªæœ‰ 10110-10115 ç«¯å£è¢«æ˜ å°„åˆ°å…¬ç½‘ï¼Œå…¶ä»–ç«¯å£æ— æ³•ä»å¤–éƒ¨è®¿é—®
                    if 'typ relay' not in candidate_str:
                        logger.info(f"Skipping non-relay candidate (port not accessible): {candidate_str[:60]}...")
                        continue

                    # Send candidate to client
                    await websocket.send_json({
                        "type": "webrtc_ice_candidate",
                        "candidate": {
                            "candidate": candidate_str,
                            "sdpMLineIndex": sdp_mline_index,
                            "sdpMid": sdp_mid
                        }
                    })
                    logger.info(f"Sent relay ICE candidate to client for session {session_id}: {candidate_str[:60]}...")

            logger.info(f"Finished sending ICE candidates for session {session_id}")
        except Exception as e:
            logger.error(f"Failed to extract and send ICE candidates: {e}")

    def _modify_sdp_for_public_ip(self, sdp: str) -> str:
        """
        ä¿®æ”¹SDPï¼Œå°†å†…ç½‘IPæ›¿æ¢ä¸ºå…¬ç½‘IPï¼Œå¹¶åªä¿ç•™relayç±»å‹çš„candidates

        Args:
            sdp: åŸå§‹SDPå­—ç¬¦ä¸²

        Returns:
            str: ä¿®æ”¹åçš„SDPå­—ç¬¦ä¸²
        """
        config = get_webrtc_config()
        public_ip = config['public_ip']

        # æ›¿æ¢ c= è¡Œä¸­çš„IPåœ°å€
        # c=IN IP4 192.168.x.x -> c=IN IP4 51.161.209.200
        sdp = re.sub(r'c=IN IP4 \d+\.\d+\.\d+\.\d+', f'c=IN IP4 {public_ip}', sdp)

        # è¿‡æ»¤candidatesï¼šåªä¿ç•™relayç±»å‹ï¼Œç§»é™¤hostå’Œsrflxç±»å‹
        # åŸå› ï¼šåªæœ‰ 10110-10115 ç«¯å£è¢«æ˜ å°„åˆ°å…¬ç½‘ï¼Œå…¶ä»–ç«¯å£ï¼ˆå¦‚ 39498ï¼‰æ— æ³•è®¿é—®
        lines = sdp.split('\n')
        modified_lines = []

        for line in lines:
            if line.startswith('a=candidate'):
                # åªä¿ç•™ typ relay çš„ candidates
                if 'typ relay' in line:
                    modified_lines.append(line)
                    logger.debug(f"Keeping relay candidate: {line}")
                else:
                    logger.debug(f"Removing non-relay candidate (inaccessible port): {line}")
            else:
                modified_lines.append(line)

        sdp = '\n'.join(modified_lines)
        logger.info(f"Modified SDP: replaced IPs with {public_ip}, kept only relay candidates")
        return sdp

    async def handle_offer(
        self,
        session_id: str,
        offer_sdp: str,
        idle_frames=None,
        websocket=None
    ) -> str:
        """
        Handle WebRTC offer from client

        Args:
            session_id: Session identifier
            offer_sdp: SDP offer from client
            idle_frames: Optional list of idle video frames for looping
            websocket: WebSocket connection for sending ICE candidates

        Returns:
            str: SDP answer
        """
        # Create peer connection if not exists
        if session_id not in self.connections:
            await self.create_peer_connection(session_id, idle_frames=idle_frames, websocket=websocket)

        pc = self.connections[session_id]

        # Set remote description (offer)
        offer = RTCSessionDescription(sdp=offer_sdp, type="offer")
        await pc.setRemoteDescription(offer)

        # Create answer
        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)

        # ç­‰å¾… ICE gathering å®Œæˆï¼ˆç¡®ä¿è·å–åˆ°æ‰€æœ‰candidatesåŒ…æ‹¬TURN relayï¼‰
        # å¦‚æœ gathering çŠ¶æ€å·²ç»æ˜¯ 'complete'ï¼Œè¿™ä¸ªå¾ªç¯ä¼šç«‹å³é€€å‡º
        max_wait = 5  # æœ€å¤šç­‰å¾…5ç§’
        waited = 0
        while pc.iceGatheringState != "complete" and waited < max_wait:
            await asyncio.sleep(0.1)
            waited += 0.1
        
        if pc.iceGatheringState != "complete":
            logger.warning(f"ICE gathering not complete after {max_wait}s, proceeding anyway")
        else:
            logger.info(f"ICE gathering completed in {waited:.2f}s")

        # ä¿®æ”¹SDPä»¥ä½¿ç”¨å…¬ç½‘IP
        modified_sdp = self._modify_sdp_for_public_ip(pc.localDescription.sdp)

        # Extract and send ICE candidates from SDP to client
        # aiortc includes ICE candidates in the SDP, but browsers expect them separately
        if websocket:
            await self._send_ice_candidates_from_sdp(modified_sdp, session_id, websocket)

        logger.info(f"WebRTC answer created for session {session_id}")
        return modified_sdp

    async def add_ice_candidate(
        self,
        session_id: str,
        candidate: dict
    ):
        """
        Add ICE candidate from client

        Args:
            session_id: Session identifier
            candidate: ICE candidate data (RTCIceCandidate object or dict)
        """
        if session_id in self.connections:
            pc = self.connections[session_id]
            try:
                # ä»å‰ç«¯ä¼ æ¥çš„candidateå¯èƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œéœ€è¦æå–å­—æ®µ
                if isinstance(candidate, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–candidateå­—æ®µ
                    candidate_str = candidate.get('candidate')
                    sdp_mid = candidate.get('sdpMid')
                    sdp_mline_index = candidate.get('sdpMLineIndex')
                else:
                    # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                    candidate_str = str(candidate)
                    sdp_mid = None
                    sdp_mline_index = None

                # ä½¿ç”¨aiortcçš„candidate_from_sdpè§£æcandidateå­—ç¬¦ä¸²
                from aiortc.sdp import candidate_from_sdp
                ice_candidate = candidate_from_sdp(candidate_str)

                # è®¾ç½®sdpMidå’ŒsdpMLineIndex
                ice_candidate.sdpMid = sdp_mid
                ice_candidate.sdpMLineIndex = sdp_mline_index

                await pc.addIceCandidate(ice_candidate)
                logger.info(f"ICE candidate added for session {session_id}: {candidate_str[:50] if candidate_str else 'None'}...")
            except Exception as e:
                logger.error(f"Failed to add ICE candidate for session {session_id}: {e}")
                logger.error(f"Candidate data: {candidate}")
        else:
            logger.warning(f"No connection found for session {session_id} when adding ICE candidate")

    async def stream_frame(self, session_id: str, frame: np.ndarray):
        """
        Stream a single frame to the client

        Args:
            session_id: Session identifier
            frame: numpy array (H, W, 3) in BGR format
        """
        if session_id in self.video_tracks:
            video_track = self.video_tracks[session_id]
            await video_track.add_frame(frame)
        else:
            logger.warning(f"No video track found for session {session_id}")

    async def stream_audio(self, session_id: str, audio_base64: str):
        """
        Stream audio to WebRTC audio track

        Args:
            session_id: Session identifier
            audio_base64: base64 encoded audio (MP3 or WAV)
        """
        if session_id not in self.audio_tracks:
            logger.warning(f"Audio track not found for session {session_id}")
            return

        try:
            # è§£ç  base64
            audio_bytes = base64.b64decode(audio_base64)

            # ä½¿ç”¨ PyAV è§£ç éŸ³é¢‘
            container = av.open(io.BytesIO(audio_bytes))
            audio_stream = container.streams.audio[0]

            # é‡é‡‡æ ·åˆ° 48kHz, s16, mono
            resampler = av.audio.resampler.AudioResampler(
                format='s16',
                layout='mono',
                rate=48000
            )

            audio_track = self.audio_tracks[session_id]

            # å¤„ç†æ‰€æœ‰éŸ³é¢‘å¸§
            chunk_count = 0
            total_duration = 0.0
            for packet in container.demux(audio_stream):
                for frame in packet.decode():
                    # é‡é‡‡æ ·
                    resampled_frames = resampler.resample(frame)

                    for resampled_frame in resampled_frames:
                        # è½¬æ¢ä¸º numpy array
                        audio_data = resampled_frame.to_ndarray()[0]  # (samples,)

                        # åˆ†å—ä¸º 960 samples (20ms)
                        for i in range(0, len(audio_data), 960):
                            chunk = audio_data[i:i+960]
                            if len(chunk) == 960:
                                await audio_track.add_audio_chunk(chunk)
                                chunk_count += 1
                                # æ¯ä¸ªchunkæ˜¯20ms
                                total_duration += 0.02
                                # æ·»åŠ 20mså»¶è¿Ÿï¼Œè®©éŸ³é¢‘æ¨é€ä¸å®é™…æ—¶é•¿åŒæ­¥
                                await asyncio.sleep(0.02)

            logger.info(f"Audio streaming completed for session {session_id}: {chunk_count} chunks, {total_duration:.2f}s")

        except Exception as e:
            logger.error(f"Failed to stream audio: {e}", exc_info=True)

    def set_idle_frames(self, session_id: str, frames: list):
        """
        Set idle video frames for a session

        Args:
            session_id: Session identifier
            frames: List of numpy arrays (H, W, 3) in BGR format
        """
        if session_id in self.video_tracks:
            video_track = self.video_tracks[session_id]
            video_track.set_idle_frames(frames)
        else:
            logger.warning(f"No video track found for session {session_id}")

    async def close_connection(self, session_id: str):
        """
        Close WebRTC connection

        Args:
            session_id: Session identifier
        """
        # æ£€æŸ¥è¿æ¥æ˜¯å¦å­˜åœ¨ï¼ˆé¿å…é‡å¤å…³é—­å¯¼è‡´ KeyErrorï¼‰
        if session_id not in self.connections:
            logger.debug(f"Connection {session_id} already closed or not found")
            return
        
        if session_id in self.video_tracks:
            await self.video_tracks[session_id].end_stream()
            del self.video_tracks[session_id]

        if session_id in self.audio_tracks:
            del self.audio_tracks[session_id]

        if session_id in self.connections:
            await self.connections[session_id].close()
            del self.connections[session_id]
        
        # æ¸…ç† WebSocket å¼•ç”¨
        if session_id in self.websockets:
            del self.websockets[session_id]

        logger.info(f"WebRTC connection closed for session {session_id}")


# Global WebRTC streamer instance
_webrtc_streamer: Optional[WebRTCStreamer] = None


def get_webrtc_streamer() -> WebRTCStreamer:
    """
    Get global WebRTC streamer instance (singleton)

    Returns:
        WebRTCStreamer: Global streamer instance
    """
    global _webrtc_streamer

    if _webrtc_streamer is None:
        _webrtc_streamer = WebRTCStreamer()
        logger.info("WebRTC streamer initialized")

    return _webrtc_streamer
