import asyncio
import json
import logging
import time
from typing import Optional, Dict
from datetime import datetime
import os
import cv2
import numpy as np

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Query, status
from fastapi.responses import JSONResponse
import uvicorn

from config import settings
from session_manager import get_session_manager
from ai_models import get_ai_engine
from webrtc_streamer import get_webrtc_streamer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# FastAPI åº”ç”¨
app = FastAPI(
    title="GPU Server WebSocket API",
    description="AI æ¨ç†å¼•æ“å®æ—¶å¯¹è¯æ¥å£",
    version="1.0.0"
)


# æ´»è·ƒçš„ WebSocket è¿æ¥ï¼ˆæŒ‰ connection_id ç´¢å¼•ï¼‰
active_connections: Dict[str, WebSocket] = {}

# Session ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆæŒ‰ engine_session_id ç´¢å¼•ï¼‰
# ç”¨äºå­˜å‚¨æ¯ä¸ª session çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯¹è¯å†å²ã€çŠ¶æ€ç­‰ï¼‰
session_contexts: Dict[str, dict] = {}


async def load_idle_frames(avatar_id: str) -> list:
    """
    Load idle video frames for WebRTC streaming

    Args:
        avatar_id: Avatar identifier

    Returns:
        List of numpy arrays (frames)
    """
    try:
        # è·å– avatar ç›®å½•
        avatar_dir = f"/workspace/gpuserver/data/avatars/{avatar_id}"

        if not os.path.exists(avatar_dir):
            logger.warning(f"Avatar directory not found: {avatar_dir}")
            return []

        # å°è¯•ä» full_imgs å­ç›®å½•åŠ è½½
        full_imgs_dir = os.path.join(avatar_dir, "full_imgs")
        if os.path.exists(full_imgs_dir):
            search_dir = full_imgs_dir
        else:
            search_dir = avatar_dir

        # è¯»å–æ‰€æœ‰å¸§
        frames = []
        frame_files = sorted([f for f in os.listdir(search_dir) if f.endswith('.png')])

        # åªåŠ è½½å‰ 125 å¸§ï¼ˆ5ç§’ @ 25fpsï¼‰
        for frame_file in frame_files[:125]:
            frame_path = os.path.join(search_dir, frame_file)
            frame = cv2.imread(frame_path)
            if frame is not None:
                frames.append(frame)

        logger.info(f"Loaded {len(frames)} idle frames for avatar {avatar_id} from {search_dir}")
        return frames

    except Exception as e:
        logger.error(f"Failed to load idle frames: {e}")
        return []


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "service": "GPU Server WebSocket API",
        "active_connections": len(active_connections)
    }


@app.websocket("/ws/{connection_id}")
@app.websocket("/ws/ws/{connection_id}")
async def websocket_endpoint(
    websocket: WebSocket,
    connection_id: str,
    token: Optional[str] = Query(None, description="engine_token or auth_token for authentication (optional)")
):
    """
    WebSocket å®æ—¶å¯¹è¯æ¥å£

    Args:
        websocket: WebSocket è¿æ¥å¯¹è±¡
        connection_id: è¿æ¥æ ‡è¯†ç¬¦ï¼ˆå¯ä»¥æ˜¯ session_id æˆ– user_{user_id}ï¼‰
        token: engine_tokenï¼ˆç”¨äºéªŒè¯ï¼‰

    è¿æ¥æ¨¡å¼:
        1. æ–°æ¨¡å¼ï¼ˆåŸºäº user_idï¼‰: connection_id = "user_{user_id}"
           - åŒä¸€ä¸ª user_id çš„æ‰€æœ‰ session å…±äº«ä¸€ä¸ª WebSocket è¿æ¥
           - æ”¯æŒä¸¤ç§å­æ¨¡å¼ï¼š
             a) æœ‰ session æ¨¡å¼ï¼šæä¾› tokenï¼Œå¯ä»¥ä½¿ç”¨ engine_session_id è·¯ç”±
             b) æ—  session æ¨¡å¼ï¼šä¸æä¾› tokenï¼Œæ¯æ¡æ¶ˆæ¯å¿…é¡»åŒ…å« tutor_id

        2. æ—§æ¨¡å¼ï¼ˆåŸºäº session_idï¼‰: connection_id = "{session_id}"
           - æ¯ä¸ª session ç‹¬ç«‹çš„ WebSocket è¿æ¥ï¼ˆå‘åå…¼å®¹ï¼‰
           - å¿…é¡»æä¾› token

    æ¶ˆæ¯æ ¼å¼:
        å®¢æˆ·ç«¯ -> æœåŠ¡å™¨:
            {
                "type": "text_webrtc" | "text" | "audio" | "webrtc_offer" | "webrtc_ice_candidate",
                "content": "ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬",
                "tutor_id": 1,  # å¿…éœ€ï¼Œç”¨äºé€‰æ‹© Avatar è§†é¢‘
                "session_id": 59,  # å¯é€‰ï¼Œç”¨äºåŒºåˆ†èŠå¤©å†å²
                "engine_session_id": "uuid-here",  # æœ‰ session æ¨¡å¼å¯é€‰
                "user_id": 123,  # WebRTC ç›¸å…³æ¶ˆæ¯å¿…éœ€
                "avatar_id": "avatar_tutor_13",  # å¯é€‰
                "kb_id": "knowledge_base_id"  # å¯é€‰
            }

        è¯´æ˜ï¼š
            - tutor_id: æ§åˆ¶ä½¿ç”¨å“ªä¸ª Avatar è§†é¢‘ï¼ˆåŒä¸€ä¸ª tutor çš„æ‰€æœ‰å­¦ç”Ÿå…±äº«åŒä¸€ä¸ª Avatarï¼‰
            - session_id: æ§åˆ¶èŠå¤©å†å²å­˜å‚¨ä½ç½®ï¼ˆåŒä¸€ä¸ªå­¦ç”Ÿå¯ä»¥æœ‰å¤šä¸ª sessionï¼‰
            - è§†é¢‘æŒ‰ tutor_id åŒºåˆ†ï¼ŒèŠå¤©è®°å½•æŒ‰ session_id åŒºåˆ†

        æœåŠ¡å™¨ -> å®¢æˆ·ç«¯:
            {
                "type": "text" | "audio" | "video" | "transcription" | "error",
                "content": "AI å“åº”å†…å®¹",
                "role": "assistant",
                "timestamp": "2024-01-01T12:00:00"
            }
    """
    manager = get_session_manager()

    # åˆ¤æ–­è¿æ¥æ¨¡å¼
    is_user_based = connection_id.startswith("user_")

    if is_user_based:
        # æ–°æ¨¡å¼ï¼šåŸºäº user_id
        user_id = connection_id.replace("user_", "")
        logger.info(f"User-based connection mode: user_id={user_id}, token_provided={token is not None}")

        # Session æ˜¯å¯é€‰çš„
        session = None

        if token:
            # å¦‚æœæä¾›äº† tokenï¼Œå°è¯•éªŒè¯å¹¶è·å– session
            verified_session_id = manager.verify_token(token)
            if verified_session_id:
                session = manager.get_session(verified_session_id)
                logger.info(f"Token verified, using session: {verified_session_id}")
            else:
                logger.warning(f"Invalid token provided, will use sessionless mode")
        else:
            logger.info(f"No token provided, using sessionless mode")

        # æ¥å—è¿æ¥ï¼ˆæ— è®ºæ˜¯å¦æœ‰ sessionï¼‰
        await websocket.accept()
        active_connections[connection_id] = websocket
        logger.info(f"WebSocket connected (user-based): connection_id={connection_id}, user_id={user_id}, has_session={session is not None}")

    else:
        # æ—§æ¨¡å¼ï¼šåŸºäº session_idï¼ˆå‘åå…¼å®¹ï¼‰
        session_id = connection_id
        logger.info(f"Session-based connection mode: session_id={session_id}")

        # éªŒè¯ token
        verified_session_id = manager.verify_token(token)
        if not verified_session_id or verified_session_id != session_id:
            logger.warning(f"Invalid token for session {session_id}")
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return

        # è·å–ä¼šè¯ä¿¡æ¯
        session = manager.get_session(session_id)
        if not session:
            logger.warning(f"Session {session_id} not found")
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return

        # æ¥å—è¿æ¥
        await websocket.accept()
        active_connections[connection_id] = websocket
        logger.info(f"WebSocket connected (session-based): session_id={session_id}, tutor_id={session.tutor_id}")

    # è·å– AI å¼•æ“ï¼ˆæŒ‰ tutor_id éš”ç¦»ï¼‰
    # åœ¨ user-based æ—  session æ¨¡å¼ä¸‹ï¼Œai_engine ä¼šåœ¨ç¬¬ä¸€æ¡æ¶ˆæ¯æ—¶åˆ›å»º
    ai_engine = None
    if session:
        ai_engine = get_ai_engine(session.tutor_id)
        logger.info(f"AI engine initialized for tutor_id={session.tutor_id}")

        # é¢„çƒ­ subprocess æ¨ç†å¼•æ“ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
        # ä½¿ç”¨ ai_engine ä¸­çš„ avatar_manager å®ä¾‹ï¼Œç¡®ä¿å¤ç”¨åŒä¸€ä¸ªå¼•æ“
        avatar_id = f"avatar_tutor_{session.tutor_id}"
        try:
            if hasattr(ai_engine, 'avatar_manager') and ai_engine.avatar_manager:
                ai_engine.avatar_manager.warmup_subprocess_engine(avatar_id)
            else:
                logger.warning(f"AI engine does not have avatar_manager, skipping warmup")
        except Exception as e:
            logger.warning(f"Failed to warmup subprocess engine for {avatar_id}: {e}")

    # è‡ªåŠ¨å‘é€å¾…æœºè§†é¢‘ï¼ˆå¦‚æœå¯ç”¨äº† Avatarï¼‰
    # æ³¨æ„ï¼šåœ¨ user-based æ¨¡å¼ä¸‹ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…ç¬¬ä¸€æ¡æ¶ˆæ¯æ¥ç¡®å®š avatar_id
    if settings.enable_avatar and not is_user_based and session:
        # åªåœ¨ session-based æ¨¡å¼ä¸‹è‡ªåŠ¨å‘é€å¾…æœºè§†é¢‘
        avatar_id = f"avatar_tutor_{session.tutor_id}"
        logger.info(f"Auto-sending idle video for avatar_id={avatar_id}")

        try:
            video_response = await ai_engine.get_idle_video(
                avatar_id=avatar_id,
                duration=5,  # 5ç§’å¾ªç¯è§†é¢‘
                fps=25
            )

            if video_response:
                await send_message(websocket, {
                    "type": "video",
                    "content": "",  # å¾…æœºè§†é¢‘æ²¡æœ‰æ–‡æœ¬å†…å®¹
                    "video": video_response,
                    "role": "assistant",
                    "timestamp": datetime.now().isoformat()
                })
                logger.info(f"Idle video sent automatically: video_size={len(video_response)} bytes")
            else:
                logger.warning("Failed to get idle video, skipping auto-send")
        except Exception as e:
            logger.error(f"Error auto-sending idle video: {e}", exc_info=True)
    elif not is_user_based and session:
        # å¦‚æœæ²¡æœ‰å¯ç”¨ Avatarï¼Œå‘é€æ¬¢è¿æ¶ˆæ¯ï¼ˆä»… session-based æ¨¡å¼ï¼‰
        await send_message(websocket, {
            "type": "text",
            "content": f"æ¬¢è¿ï¼æ‚¨å·²è¿æ¥åˆ°è™šæ‹Ÿå¯¼å¸ˆ (Tutor ID: {session.tutor_id})",
            "role": "assistant",
            "timestamp": datetime.now().isoformat()
        })

    try:
        # æ¶ˆæ¯å¤„ç†å¾ªç¯
        while True:
            # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)

            # åœ¨ user-based æ¨¡å¼ä¸‹ï¼Œä»æ¶ˆæ¯ä¸­è·å– engine_session_idï¼ˆå¯é€‰ï¼‰
            if is_user_based:
                # æ—  session æ¨¡å¼ï¼šä»æ¶ˆæ¯ä¸­è·å– tutor_id
                if not session:
                    tutor_id = message.get("tutor_id")
                    if not tutor_id:
                        await send_error(websocket, "tutor_id is required in sessionless mode")
                        continue

                    # åŠ¨æ€åˆ›å»º AI å¼•æ“
                    if not ai_engine:
                        ai_engine = get_ai_engine(tutor_id)
                        logger.info(f"AI engine created dynamically for tutor_id={tutor_id}")

                        # é¢„çƒ­ subprocess æ¨ç†å¼•æ“ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
                        # ä½¿ç”¨ ai_engine ä¸­çš„ avatar_manager å®ä¾‹ï¼Œç¡®ä¿å¤ç”¨åŒä¸€ä¸ªå¼•æ“
                        avatar_id = f"avatar_tutor_{tutor_id}"
                        try:
                            if hasattr(ai_engine, 'avatar_manager') and ai_engine.avatar_manager:
                                ai_engine.avatar_manager.warmup_subprocess_engine(avatar_id)
                            else:
                                logger.warning(f"AI engine does not have avatar_manager, skipping warmup")
                        except Exception as e:
                            logger.warning(f"Failed to warmup subprocess engine for {avatar_id}: {e}")

                    # ç›´æ¥å¤„ç†æ¶ˆæ¯ï¼ˆæ—  sessionï¼‰
                    await handle_message(websocket, None, message, ai_engine, is_user_based)
                else:
                    # æœ‰ session æ¨¡å¼
                    engine_session_id = message.get("engine_session_id")

                    # å¦‚æœæ²¡æœ‰æä¾› engine_session_idï¼Œä½¿ç”¨é»˜è®¤çš„ sessionï¼ˆè¿æ¥æ—¶éªŒè¯çš„é‚£ä¸ªï¼‰
                    if not engine_session_id:
                        engine_session_id = session.session_id
                        logger.info(f"No engine_session_id provided, using default session: {engine_session_id}")

                    # è·å–æˆ–åˆ›å»º session ä¸Šä¸‹æ–‡
                    if engine_session_id not in session_contexts:
                        # éªŒè¯ engine_session_id æ˜¯å¦æœ‰æ•ˆ
                        target_session = manager.get_session(engine_session_id)
                        if not target_session:
                            await send_error(websocket, f"Invalid engine_session_id: {engine_session_id}")
                            continue

                        # åˆ›å»º session ä¸Šä¸‹æ–‡
                        session_contexts[engine_session_id] = {
                            "session": target_session,
                            "ai_engine": get_ai_engine(target_session.tutor_id)
                        }
                        logger.info(f"Created session context for engine_session_id={engine_session_id}")

                    # æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´
                    manager.update_activity(engine_session_id)

                    # å¤„ç†æ¶ˆæ¯ï¼ˆä½¿ç”¨ engine_session_id å¯¹åº”çš„ sessionï¼‰
                    ctx = session_contexts[engine_session_id]
                    await handle_message(websocket, ctx["session"], message, ctx["ai_engine"], is_user_based)

            else:
                # æ—§æ¨¡å¼ï¼šä½¿ç”¨ connection_id ä½œä¸º session_id
                session_id = connection_id
                manager.update_activity(session_id)
                await handle_message(websocket, session, message, ai_engine, is_user_based)

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected: connection_id={connection_id}")
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON: {e}")
        await send_error(websocket, "Invalid message format")
    except Exception as e:
        logger.error(f"Error in WebSocket handler: {e}", exc_info=True)
        await send_error(websocket, f"Internal server error: {str(e)}")
    finally:
        # æ¸…ç†è¿æ¥
        active_connections.pop(connection_id, None)

        # åœ¨ user-based æ¨¡å¼ä¸‹ï¼Œæ¸…ç†è¯¥ç”¨æˆ·çš„æ‰€æœ‰ session ä¸Šä¸‹æ–‡
        if is_user_based:
            # æ³¨æ„ï¼šè¿™é‡Œä¸æ¸…ç† session_contextsï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½ä¼šé‡æ–°è¿æ¥
            # session_contexts ä¼šåœ¨ session è¿‡æœŸæ—¶è‡ªåŠ¨æ¸…ç†
            logger.info(f"Connection cleaned up (user-based): connection_id={connection_id}")
        else:
            logger.info(f"Connection cleaned up (session-based): connection_id={connection_id}")


async def stream_audio_video(
    ai_engine,
    text: str,
    avatar_id: str,
    user_id: int,
    websocket: WebSocket
):
    """
    å¹¶è¡Œå¤„ç†éŸ³è§†é¢‘ç”Ÿæˆå’Œæ¨é€ï¼ˆé€å¸§æµå¼ï¼‰
    
    æ¶æ„ï¼ˆå‚è€ƒ virtual-tutorï¼‰:
    1. TTS ç”ŸæˆéŸ³é¢‘
    2. MuseTalk realtime_engine ç”Ÿæˆå¸§ â†’ res_frame_queue
    3. process_frames çº¿ç¨‹: res_frame_queue â†’ video_track.frame_queue
    4. WebRTC track.recv(): frame_queue â†’ å®¢æˆ·ç«¯
    
    Args:
        ai_engine: AI å¼•æ“å®ä¾‹
        text: å®Œæ•´æ–‡æœ¬
        avatar_id: Avatar ID
        user_id: ç”¨æˆ· ID
        websocket: WebSocket è¿æ¥ï¼ˆç”¨äºé”™è¯¯é€šçŸ¥ï¼‰
    """
    try:
        streamer = get_webrtc_streamer()
        session_id = f"user_{user_id}"
        
        # è·å– video_trackï¼ˆWebRTC trackï¼‰
        if session_id not in streamer.video_tracks:
            logger.error(f"No video track found for session {session_id}")
            await send_error(websocket, "WebRTC connection not established")
            return
        
        video_track = streamer.video_tracks[session_id]
        
        # ====== é˜¶æ®µ2: TTS ç”Ÿæˆï¼ˆå®Œæ•´éŸ³é¢‘ï¼‰======
        logger.info(f"[Pipeline] Stage 2: TTS generation...")
        audio_data = await ai_engine.synthesize_speech(text)
        logger.info(f"[Pipeline] Stage 2 complete: audio_length={len(audio_data)}")
        
        # ====== é˜¶æ®µ3: å¯åŠ¨ realtime_engine ç”Ÿæˆå¸§åˆ° res_frame_queue ======
        logger.info(f"[Pipeline] Stage 3: Starting realtime frame generation...")
        
        # å…ˆå¯åŠ¨è§†é¢‘ç”Ÿæˆï¼Œç­‰ç¬¬ä¸€å¸§å‡ºç°åå†å¯åŠ¨éŸ³é¢‘ï¼ˆå®ç°éŸ³è§†é¢‘åŒæ­¥ï¼‰
        audio_task = None
        audio_started = False
        
        frame_count = 0
        async for frame in ai_engine.video_engine.generate_frames_stream(
            audio_data=audio_data, avatar_id=avatar_id, fps=25
        ):
            # åœ¨æ¨é€ç¬¬ä¸€å¸§è§†é¢‘æ—¶ï¼ŒåŒæ—¶å¯åŠ¨éŸ³é¢‘æ¨é€ï¼ˆå®ç°éŸ³è§†é¢‘åŒæ­¥ï¼‰
            if not audio_started:
                audio_task = asyncio.create_task(
                    streamer.stream_audio(session_id, audio_data)
                )
                audio_started = True
                logger.info(f"[Pipeline] ğŸ”Š Audio streaming started (synchronized with first video frame)")
            
            # ç›´æ¥å°†å¸§æ¨é€åˆ° video_track çš„ frame_queue
            await video_track.frame_queue.put(frame)
            frame_count += 1
            if frame_count == 1:
                logger.info(f"[Pipeline] âš¡ First frame pushed to WebRTC queue")
            if frame_count % 20 == 0:
                logger.info(f"[Pipeline] ğŸ“¤ Pushed {frame_count} frames to WebRTC (qsize={video_track.frame_queue.qsize()})")
        
        logger.info(f"[Pipeline] Stage 3 complete: {frame_count} frames generated")
        
        # ç­‰å¾…éŸ³é¢‘å®Œæˆ
        if audio_task:
            await audio_task
        logger.info(f"[Pipeline] âœ… Complete: {frame_count} frames, audio delivered")
        
    except Exception as e:
        logger.error(f"[Pipeline] âŒ Failed: {e}", exc_info=True)
        await send_error(websocket, f"Processing failed: {str(e)}")


async def handle_message(websocket: WebSocket, session, message: dict, ai_engine, is_user_based: bool = False):
    """
    å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯

    Args:
        websocket: WebSocket è¿æ¥
        session: ä¼šè¯å¯¹è±¡ï¼ˆå¯ä»¥ä¸º Noneï¼Œåœ¨ sessionless æ¨¡å¼ä¸‹ï¼‰
        message: å®¢æˆ·ç«¯æ¶ˆæ¯
        ai_engine: AI å¼•æ“å®ä¾‹
        is_user_based: æ˜¯å¦ä¸º user-based æ¨¡å¼
    """
    msg_type = message.get("type")
    content = message.get("content", "")

    session_id = session.session_id if session else "sessionless"
    logger.info(f"Received message: session_id={session_id}, type={msg_type}")

    try:
        if msg_type == "init":
            # å¤„ç†åˆå§‹åŒ–æ¶ˆæ¯ - è¿”å›å¾…æœºè§†é¢‘ï¼ˆidle videoï¼‰
            avatar_id = message.get("avatar_id")  # å¿…éœ€çš„ avatar_id

            if not avatar_id:
                await send_error(websocket, "avatar_id is required for init message")
                return

            logger.info(f"Processing init message: avatar_id={avatar_id}")

            # è·å–å¾…æœºè§†é¢‘ï¼ˆä¸ç”Ÿæˆ TTSï¼Œåªè¿”å›å¾ªç¯çš„é™æ€è§†é¢‘ï¼‰
            video_response = None
            if settings.enable_avatar:
                logger.info(f"Getting idle video for avatar_id={avatar_id}")
                video_response = await ai_engine.get_idle_video(
                    avatar_id=avatar_id,
                    duration=5,  # 5ç§’å¾ªç¯è§†é¢‘
                    fps=25
                )

            if video_response:
                # æ„å»ºå“åº”æ¶ˆæ¯ - åªåŒ…å«è§†é¢‘ï¼Œä¸åŒ…å«éŸ³é¢‘å’Œæ–‡æœ¬
                response_message = {
                    "type": "video",
                    "content": "",  # å¾…æœºè§†é¢‘æ²¡æœ‰æ–‡æœ¬å†…å®¹
                    "video": video_response,  # base64 ç¼–ç çš„è§†é¢‘
                    "role": "assistant",
                    "timestamp": datetime.now().isoformat()
                }
                logger.info(f"Sending idle video: video_size={len(video_response)} bytes")
            else:
                # å¦‚æœæ— æ³•è·å–å¾…æœºè§†é¢‘ï¼Œè¿”å›é”™è¯¯
                await send_error(websocket, "Failed to get idle video")
                return

            # å‘é€å“åº”
            await send_message(websocket, response_message)
            logger.info("Idle video sent successfully")

        elif msg_type == "text_webrtc":
            # å¤„ç†æ–‡æœ¬æ¶ˆæ¯ - WebRTC å®æ—¶æµå¼ä¼ è¾“æ¨¡å¼ï¼ˆä¸‰é˜¶æ®µæµå¼ Pipelineï¼‰
            avatar_id = message.get("avatar_id")  # å¿…éœ€çš„ avatar_id
            user_id = message.get("user_id")  # å‰ç«¯ä¼ å…¥çš„ user_id
            engine_session_id = message.get("engine_session_id")  # ç”¨äºè·¯ç”±çš„ session_id

            if not avatar_id:
                await send_error(websocket, "avatar_id is required for WebRTC streaming")
                return

            if not user_id:
                await send_error(websocket, "user_id is required for WebRTC streaming")
                return

            # è·å– tutor_idã€kb_id å’Œ session_idï¼ˆä» session æˆ–æ¶ˆæ¯ä¸­ï¼‰
            tutor_id = session.tutor_id if session else message.get("tutor_id")
            kb_id = session.kb_id if session else message.get("kb_id")
            session_id_for_chat = message.get("session_id")  # ç”¨äºåŒºåˆ†èŠå¤©å†å²

            # åœ¨ user-based æ¨¡å¼ä¸‹ï¼Œengine_session_id åº”è¯¥å·²ç»åœ¨å¤–å±‚å¤„ç†
            # è¿™é‡Œè®°å½•æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
            session_id_log = session.session_id if session else "sessionless"
            logger.info(f"Processing text with WebRTC streaming: avatar_id={avatar_id}, user_id={user_id}, engine_session_id={engine_session_id}, session_id={session_id_log}")

            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # ====== é˜¶æ®µ1: LLM æµå¼ç”Ÿæˆ ======
            full_text = ""
            first_token_time = None

            async for token in ai_engine.stream_text_response(
                text=content, tutor_id=tutor_id, kb_id=kb_id, session_id=session_id_for_chat
            ):
                # è®°å½•é¦– token æ—¶é—´
                if first_token_time is None:
                    first_token_time = time.time()
                    logger.info(f"âš¡ First token: {first_token_time - start_time:.2f}s")

                # ç«‹å³å‘é€ token
                await send_message(websocket, {
                    "type": "text_stream",
                    "token": token,
                    "role": "assistant",
                    "timestamp": datetime.now().isoformat()
                })
                
                # è°ƒè¯•ï¼šè®°å½•å‘é€
                if first_token_time is not None and (time.time() - first_token_time) < 0.1:
                    logger.info(f"ğŸ“¤ Sent first text_stream token: {token[:20]}...")

                full_text += token

            # å‘é€å®Œæˆä¿¡å·
            await send_message(websocket, {
                "type": "text_complete",
                "content": full_text,
                "role": "assistant",
                "timestamp": datetime.now().isoformat()
            })

            text_complete_time = time.time()
            logger.info(f"Text complete: {text_complete_time - start_time:.2f}s")

            # å‘é€çŠ¶æ€æ¶ˆæ¯ï¼Œå‘ŠçŸ¥å‰ç«¯éŸ³è§†é¢‘ç”Ÿæˆå·²å¯åŠ¨
            await send_message(websocket, {
                "type": "processing_status",
                "status": "generating_audio_video",
                "message": "æ­£åœ¨ç”ŸæˆéŸ³è§†é¢‘...",
                "timestamp": datetime.now().isoformat()
            })

            # ====== é˜¶æ®µ2+3: éŸ³è§†é¢‘å¼‚æ­¥å¤„ç† ======
            asyncio.create_task(
                stream_audio_video(ai_engine, full_text, avatar_id, user_id, websocket)
            )

            logger.info("WebRTC streaming response initiated (audio + video via WebRTC)")

        elif msg_type == "text":
            # å¤„ç†æ–‡æœ¬æ¶ˆæ¯ - æµå¼å“åº”æ¨¡å¼ï¼ˆç«‹å³å‘é€æ–‡æœ¬ï¼‰
            avatar_id = message.get("avatar_id")  # å¯é€‰çš„ avatar_id
            user_id = message.get("user_id")  # ç”¨æˆ· ID (ç”¨äº WebRTC éŸ³é¢‘)

            # è·å– tutor_idã€kb_id å’Œ session_idï¼ˆä» session æˆ–æ¶ˆæ¯ä¸­ï¼‰
            tutor_id = session.tutor_id if session else message.get("tutor_id")
            kb_id = session.kb_id if session else message.get("kb_id")
            session_id_for_chat = message.get("session_id")  # ç”¨äºåŒºåˆ†èŠå¤©å†å²

            # 1. LLM: ç”Ÿæˆå“åº”
            response = await ai_engine.process_text(
                text=content,
                tutor_id=tutor_id,
                kb_id=kb_id,
                session_id=session_id_for_chat  # ä¼ é€’ session_id ç”¨äºèŠå¤©å†å²
            )

            # 2. ç«‹å³å‘é€æ–‡æœ¬å“åº”
            await send_message(websocket, {
                "type": "text",
                "content": response,
                "role": "assistant",
                "timestamp": datetime.now().isoformat()
            })
            logger.info("Text response sent immediately")

            # 3. TTS: æ–‡æœ¬è½¬è¯­éŸ³
            audio_response = await ai_engine.synthesize_speech(response)

            # 4. å‘é€éŸ³é¢‘ (é€šè¿‡ WebRTC æˆ– WebSocket,å–å†³äºæ˜¯å¦æœ‰ user_id)
            if user_id:
                # é€šè¿‡ WebRTC å‘é€éŸ³é¢‘ï¼ˆä½¿ç”¨å…¨å±€å¯¼å…¥çš„ get_webrtc_streamerï¼‰
                streamer = get_webrtc_streamer()
                asyncio.create_task(streamer.stream_audio(f"user_{user_id}", audio_response))
                logger.info(f"Audio sent via WebRTC for user {user_id}")
            else:
                # å›é€€åˆ° WebSocket å‘é€éŸ³é¢‘ (å‘åå…¼å®¹)
                await send_message(websocket, {
                    "type": "audio",
                    "content": response,
                    "audio": audio_response,  # base64 ç¼–ç çš„éŸ³é¢‘
                    "role": "assistant",
                    "timestamp": datetime.now().isoformat()
                })
                logger.info("Audio response sent via WebSocket (no user_id provided)")

            # 5. å¯é€‰ï¼šåå°ç”Ÿæˆè§†é¢‘ï¼ˆä¸é˜»å¡ï¼‰
            if settings.enable_avatar and avatar_id:
                logger.info(f"Starting background video generation for avatar_id={avatar_id}")

                # åœ¨åå°å¼‚æ­¥ç”Ÿæˆè§†é¢‘
                async def generate_video_background():
                    try:
                        video_response = await ai_engine.generate_video(
                            audio_data=audio_response,
                            avatar_id=avatar_id,
                            fps=25
                        )

                        if video_response:
                            # è§†é¢‘ç”Ÿæˆå®Œæˆåå‘é€
                            await send_message(websocket, {
                                "type": "video",
                                "content": response,
                                "video": video_response,
                                "role": "assistant",
                                "timestamp": datetime.now().isoformat()
                            })
                            logger.info(f"Background video sent: video_size={len(video_response)} bytes")
                    except Exception as e:
                        logger.error(f"Background video generation failed: {e}")

                # å¯åŠ¨åå°ä»»åŠ¡ï¼ˆä¸ç­‰å¾…ï¼‰
                asyncio.create_task(generate_video_background())

        elif msg_type == "audio":
            # å¤„ç†éŸ³é¢‘æ¶ˆæ¯
            audio_data = message.get("data", "")
            avatar_id = message.get("avatar_id")  # å¯é€‰çš„ avatar_id

            logger.info(f"Audio message received: avatar_id={avatar_id}, enable_avatar={settings.enable_avatar}")

            # ASR: éŸ³é¢‘è½¬æ–‡æœ¬
            transcription = await ai_engine.process_audio(audio_data)

            # å‘é€è½¬å½•ç»“æœ
            await send_message(websocket, {
                "type": "transcription",
                "content": transcription,
                "role": "user",
                "timestamp": datetime.now().isoformat()
            })

            # LLM: ç”Ÿæˆå“åº”
            tutor_id = session.tutor_id if session else message.get("tutor_id")
            kb_id = session.kb_id if session else message.get("kb_id")
            session_id_for_chat = message.get("session_id")  # ç”¨äºåŒºåˆ†èŠå¤©å†å²

            response = await ai_engine.process_text(
                text=transcription,
                tutor_id=tutor_id,
                kb_id=kb_id,
                session_id=session_id_for_chat  # ä¼ é€’ session_id ç”¨äºèŠå¤©å†å²
            )

            # TTS: æ–‡æœ¬è½¬è¯­éŸ³
            audio_response = await ai_engine.synthesize_speech(response)

            # å¦‚æœå¯ç”¨äº† Avatar ä¸”æä¾›äº† avatar_idï¼Œç”Ÿæˆè§†é¢‘
            video_response = None
            if settings.enable_avatar and avatar_id:
                logger.info(f"Generating video for avatar_id={avatar_id}")
                video_response = await ai_engine.generate_video(
                    audio_data=audio_response,
                    avatar_id=avatar_id,
                    fps=25
                )

            # æ„å»ºå“åº”æ¶ˆæ¯
            response_message = {
                "type": "video" if video_response else "audio",
                "content": response,
                "audio": audio_response,  # base64 ç¼–ç çš„éŸ³é¢‘
                "role": "assistant",
                "timestamp": datetime.now().isoformat()
            }

            # å¦‚æœæœ‰è§†é¢‘ï¼Œæ·»åŠ è§†é¢‘æ•°æ®
            if video_response:
                response_message["video"] = video_response  # base64 ç¼–ç çš„è§†é¢‘

            # å‘é€å“åº”
            await send_message(websocket, response_message)

        elif msg_type == "webrtc_offer":
            # å¤„ç† WebRTC offer
            offer_sdp = message.get("sdp")
            user_id = message.get("user_id")  # å‰ç«¯ä¼ å…¥çš„ user_id
            avatar_id = message.get("avatar_id", "avatar_tutor_13")  # å¯é€‰çš„ avatar_id

            if not offer_sdp:
                await send_error(websocket, "SDP offer is required")
                return

            if not user_id:
                await send_error(websocket, "user_id is required for WebRTC")
                return

            session_id_log = session.session_id if session else "sessionless"
            logger.info(f"Received WebRTC offer from session {session_id_log}, user_id={user_id}")

            # è·å– WebRTC streamer
            webrtc_streamer = get_webrtc_streamer()

            # åŠ è½½å¾…æœºè§†é¢‘å¸§
            idle_frames = await load_idle_frames(avatar_id)

            # å¤„ç† offer å¹¶ç”Ÿæˆ answerï¼ˆä½¿ç”¨ user_idï¼ŒåŒä¸€ç”¨æˆ·å…±äº«ï¼‰
            # ä¼ é€’ websocket ä»¥ä¾¿å‘é€ ICE candidates
            answer_sdp = await webrtc_streamer.handle_offer(
                session_id=f"user_{user_id}",  # ä½¿ç”¨ user_id ä½œä¸ºæ ‡è¯†
                offer_sdp=offer_sdp,
                idle_frames=idle_frames,  # ä¼ å…¥å¾…æœºå¸§
                websocket=websocket  # ä¼ å…¥ WebSocket è¿æ¥
            )

            # å‘é€ answer å›å®¢æˆ·ç«¯
            await send_message(websocket, {
                "type": "webrtc_answer",
                "sdp": answer_sdp,
                "timestamp": datetime.now().isoformat()
            })

            logger.info(f"WebRTC answer sent to user {user_id} with idle frames")

        elif msg_type == "webrtc_ice_candidate":
            # å¤„ç† ICE candidate
            candidate = message.get("candidate")
            user_id = message.get("user_id")  # å‰ç«¯ä¼ å…¥çš„ user_id

            if not candidate:
                await send_error(websocket, "ICE candidate is required")
                return

            if not user_id:
                await send_error(websocket, "user_id is required for WebRTC")
                return

            session_id_log = session.session_id if session else "sessionless"
            logger.info(f"Received ICE candidate from session {session_id_log}, user_id={user_id}")

            # è·å– WebRTC streamer
            webrtc_streamer = get_webrtc_streamer()

            # æ·»åŠ  ICE candidateï¼ˆä½¿ç”¨ user_idï¼‰
            await webrtc_streamer.add_ice_candidate(
                session_id=f"user_{user_id}",  # ä½¿ç”¨ user_id ä½œä¸ºæ ‡è¯†
                candidate=candidate
            )

        else:
            await send_error(websocket, f"Unsupported message type: {msg_type}")

    except Exception as e:
        logger.error(f"Error processing message: {e}", exc_info=True)
        await send_error(websocket, f"Failed to process message: {str(e)}")


async def send_message(websocket: WebSocket, message: dict):
    """å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯"""
    try:
        await websocket.send_json(message)
    except Exception as e:
        logger.error(f"Failed to send message: {e}")


async def send_error(websocket: WebSocket, error: str):
    """å‘é€é”™è¯¯æ¶ˆæ¯"""
    await send_message(websocket, {
        "type": "error",
        "content": error,
        "timestamp": datetime.now().isoformat()
    })


def main():
    """å¯åŠ¨ WebSocket æœåŠ¡"""
    uvicorn.run(
        app,
        host=settings.websocket_host,
        port=settings.websocket_port,
        log_level="info"
    )


if __name__ == "__main__":
    main()
